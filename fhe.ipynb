{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHE Aging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyaging as pya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> ðŸ—ï¸ Starting download_example_data function\n",
      "|-----------> Data found in pyaging_data/blood_chemistry_example.pkl\n",
      "|-----> ðŸŽ‰ Done! [0.0024s]\n"
     ]
    }
   ],
   "source": [
    "pya.data.download_example_data('blood_chemistry_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('pyaging_data/blood_chemistry_example.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> ðŸ—ï¸ Starting df_to_adata function\n",
      "|-----> âš™ï¸ Create anndata object started\n",
      "|-----> âœ… Create anndata object finished [0.0056s]\n",
      "|-----> âš™ï¸ Add metadata to anndata started\n",
      "|-----------? No metadata provided. Leaving adata.obs empty\n",
      "|-----> âš ï¸ Add metadata to anndata finished [0.0007s]\n",
      "|-----> âš™ï¸ Log data statistics started\n",
      "|-----------> There are 30 observations\n",
      "|-----------> There are 10 features\n",
      "|-----------> Total missing values: 0\n",
      "|-----------> Percentage of missing values: 0.00%\n",
      "|-----> âœ… Log data statistics finished [0.0017s]\n",
      "|-----> âš™ï¸ Impute missing values started\n",
      "|-----------> No missing values found. No imputation necessary\n",
      "|-----> âœ… Impute missing values finished [0.0018s]\n",
      "|-----> ðŸŽ‰ Done! [0.0154s]\n"
     ]
    }
   ],
   "source": [
    "adata = pya.preprocess.df_to_adata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marshal\n",
    "import math\n",
    "import ntpath\n",
    "import os\n",
    "import types\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from anndata.experimental.pytorch import AnnLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pyaging.logger import LoggerManager, main_tqdm, silence_logger\n",
    "from pyaging.models import *\n",
    "from pyaging.utils import download, load_clock_metadata, progress\n",
    "from pyaging.predict._postprocessing import *\n",
    "from pyaging.predict._preprocessing import *\n",
    "\n",
    "@progress(\"Predict ages with model\")\n",
    "def predict_ages_with_model(\n",
    "    adata: anndata.AnnData,\n",
    "    model: pyagingModel,\n",
    "    device: str,\n",
    "    batch_size: int,\n",
    "    logger,\n",
    "    indent_level: int = 2,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Predict biological ages using a trained model and input data.\n",
    "\n",
    "    This function takes a machine learning model and input data, and returns predictions made by the model.\n",
    "    It's primarily used for estimating biological ages based on various biological markers. The function\n",
    "    assumes that the model is already trained. A dataloader is used because of possible memory constraints\n",
    "    for large datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : anndata.AnnData\n",
    "        The AnnData object containing the dataset. Its `.X` attribute is expected to be a matrix where rows\n",
    "        correspond to samples and columns correspond to features.\n",
    "\n",
    "    model : pyagingModel\n",
    "        The pyagingModel of the aging clock of interest.\n",
    "\n",
    "    device : str\n",
    "        Device to move AnnData to during inference. Eithe 'cpu' or 'cuda'.\n",
    "\n",
    "    batch_size : int\n",
    "        Batch size for the AnnLoader object to predict age.\n",
    "\n",
    "    logger : Logger\n",
    "        A logger object for logging the progress or any relevant information during the prediction process.\n",
    "\n",
    "    indent_level : int, optional\n",
    "        The indentation level for logging messages, by default 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : torch.Tensor\n",
    "        An array of predicted ages or biological markers, as returned by the model.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Ensure that the data is preprocessed (e.g., scaled, normalized) as required by the model before\n",
    "    passing it to this function. The model should be in evaluation mode if it's a type that has different\n",
    "    behavior during training and inference (e.g., PyTorch models).\n",
    "\n",
    "    The exact nature of the predictions (e.g., age, biological markers) depends on the model being used.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = load_pretrained_model()\n",
    "    >>> predictions = predict_ages_with_model(model, \"cpu\", logger)\n",
    "    >>> print(predictions[:5])\n",
    "    [34.5, 29.3, 47.8, 50.1, 42.6]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # If there is a preprocessing step\n",
    "    if model.preprocess_name is not None:\n",
    "        logger.info(\n",
    "            f\"The preprocessing method is {model.preprocess_name}\",\n",
    "            indent_level=indent_level + 1,\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"There is no preprocessing necessary\", indent_level=indent_level + 1)\n",
    "\n",
    "    # If there is a postprocessing step\n",
    "    if model.postprocess_name is not None:\n",
    "        logger.info(\n",
    "            f\"The postprocessing method is {model.postprocess_name}\",\n",
    "            indent_level=indent_level + 1,\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"There is no postprocessing necessary\", indent_level=indent_level + 1)\n",
    "\n",
    "    # Create an AnnLoader\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    dataloader = AnnLoader(adata, batch_size=batch_size, use_cuda=use_cuda)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for param in model.parameters():\n",
    "    #         param.zero_()\n",
    "\n",
    "    # Use the AnnLoader for batched prediction\n",
    "    predictions = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in main_tqdm(dataloader, indent_level=indent_level + 1, logger=logger):\n",
    "            batch_pred = model(batch.obsm[f\"X_{model.metadata['clock_name']}\"])\n",
    "            predictions.append(batch_pred)\n",
    "    # Concatenate all batch predictions\n",
    "    predictions = torch.cat(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> ðŸ—ï¸ Starting predict_age function\n",
      "|-----> âš™ï¸ Set PyTorch device started\n",
      "|-----------> Using device: cpu\n",
      "|-----> âœ… Set PyTorch device finished [0.0025s]\n",
      "|-----> ðŸ•’ Processing clock: phenoage\n",
      "|-----------> âš™ï¸ Load clock started\n",
      "|-----------------> Data found in pyaging_data/phenoage.pt\n",
      "Layer: base_model.linear.weight | Size: torch.Size([1, 10]) | Values : tensor([[-0.0336,  0.0095,  0.1953,  0.0954, -0.0120,  0.0268,  0.3306,  0.0019,\n",
      "          0.0554,  0.0804]], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: base_model.linear.bias | Size: torch.Size([1]) | Values : tensor([-19.9067], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "|-----------> âœ… Load clock finished [0.0066s]\n",
      "|-----------> âš™ï¸ Check features in adata started\n",
      "|-----------------> All features are present in adata.var_names.\n",
      "|-----------> âœ… Check features in adata finished [0.0008s]\n",
      "|-----------> âš™ï¸ Predict ages with model started\n",
      "|-----------------> There is no preprocessing necessary\n",
      "|-----------------> The postprocessing method is mortality_to_phenoage\n",
      "|-----------------> in progress: 100.0000%\n",
      "|-----------> âœ… Predict ages with model finished [0.0053s]\n",
      "|-----------> âš™ï¸ Add predicted ages and clock metadata to adata started\n",
      "|-----------> âœ… Add predicted ages and clock metadata to adata finished [0.0006s]\n",
      "|-----> ðŸŽ‰ Done! [0.0769s]\n"
     ]
    }
   ],
   "source": [
    "pya.pred.predict_age_fhe(adata, predict_ages_with_model, 'PhenoAge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pya.pred.predict_age(adata, predict_ages_with_model, 'PhenoAge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenoage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patient1</th>\n",
       "      <td>74.348798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient2</th>\n",
       "      <td>67.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient3</th>\n",
       "      <td>74.789739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient4</th>\n",
       "      <td>46.991769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient5</th>\n",
       "      <td>44.559486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           phenoage\n",
       "patient1  74.348798\n",
       "patient2  67.372000\n",
       "patient3  74.789739\n",
       "patient4  46.991769\n",
       "patient5  44.559486"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 30 Ã— 10\n",
       "    obs: 'phenoage'\n",
       "    var: 'percent_na'\n",
       "    uns: 'phenoage_percent_na', 'phenoage_missing_features', 'phenoage_metadata'\n",
       "    layers: 'X_original'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenoage</th>\n",
       "      <th>chronological_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patient1</th>\n",
       "      <td>74.348798</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient2</th>\n",
       "      <td>67.372000</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient3</th>\n",
       "      <td>74.789739</td>\n",
       "      <td>66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient4</th>\n",
       "      <td>46.991769</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient5</th>\n",
       "      <td>44.559486</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient6</th>\n",
       "      <td>72.509460</td>\n",
       "      <td>76.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient7</th>\n",
       "      <td>57.377050</td>\n",
       "      <td>55.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient8</th>\n",
       "      <td>31.779798</td>\n",
       "      <td>34.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient9</th>\n",
       "      <td>50.356509</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient10</th>\n",
       "      <td>67.696706</td>\n",
       "      <td>52.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient11</th>\n",
       "      <td>62.601978</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient12</th>\n",
       "      <td>41.735924</td>\n",
       "      <td>45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient13</th>\n",
       "      <td>82.238745</td>\n",
       "      <td>62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient14</th>\n",
       "      <td>56.677500</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient15</th>\n",
       "      <td>46.402083</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phenoage  chronological_age\n",
       "patient1   74.348798               70.2\n",
       "patient2   67.372000               76.5\n",
       "patient3   74.789739               66.4\n",
       "patient4   46.991769               46.5\n",
       "patient5   44.559486               42.3\n",
       "patient6   72.509460               76.9\n",
       "patient7   57.377050               55.1\n",
       "patient8   31.779798               34.6\n",
       "patient9   50.356509               47.3\n",
       "patient10  67.696706               52.3\n",
       "patient11  62.601978               47.2\n",
       "patient12  41.735924               45.2\n",
       "patient13  82.238745               62.9\n",
       "patient14  56.677500               40.7\n",
       "patient15  46.402083               18.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.DataFrame({\n",
    "    'phenoage': adata.obs[\"phenoage\"],\n",
    "    'chronological_age': df[\"age\"]\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "combined_df[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Torch Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhenoAge(pyagingModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return x\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        \"\"\"\n",
    "        Applies a convertion from a CDF of the mortality score from a Gompertz\n",
    "        distribution to phenotypic age.\n",
    "        \"\"\"\n",
    "        # lambda\n",
    "        l = torch.tensor(0.0192, device=x.device, dtype=x.dtype)\n",
    "        mortality_score = 1 - torch.exp(-torch.exp(x) * (torch.exp(120 * l) - 1) / l)\n",
    "        age = 141.50225 + torch.log(-0.00553 * torch.log(1 - mortality_score)) / 0.090165\n",
    "        return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.linear.weight | Size: torch.Size([1, 10]) | Values : tensor([[-0.0336,  0.0095,  0.1953,  0.0954, -0.0120,  0.0268,  0.3306,  0.0019,\n",
      "          0.0554,  0.0804]], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: base_model.linear.bias | Size: torch.Size([1]) | Values : tensor([-19.9067], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PhenoAge(\n",
       "  (base_model): LinearModel(\n",
       "    (linear): Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "weights_path = f\"./pyaging_data/phenoage.pt\"\n",
    "clock = torch.load(weights_path, weights_only=False)\n",
    "\n",
    "for name, param in clock.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "\n",
    "# Prepare clock for inference\n",
    "clock.to(torch.float64)\n",
    "clock.to(device)\n",
    "clock.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 30 Ã— 10\n",
       "    obs: 'phenoage'\n",
       "    var: 'percent_na'\n",
       "    uns: 'phenoage_percent_na', 'phenoage_missing_features', 'phenoage_metadata'\n",
       "    layers: 'X_original'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phenoage'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clock.metadata['clock_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenoage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patient1</th>\n",
       "      <td>74.348798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient2</th>\n",
       "      <td>67.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient3</th>\n",
       "      <td>74.789739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient4</th>\n",
       "      <td>46.991769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient5</th>\n",
       "      <td>44.559486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient6</th>\n",
       "      <td>72.509460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient7</th>\n",
       "      <td>57.377050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient8</th>\n",
       "      <td>31.779798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient9</th>\n",
       "      <td>50.356509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient10</th>\n",
       "      <td>67.696706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient11</th>\n",
       "      <td>62.601978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient12</th>\n",
       "      <td>41.735924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient13</th>\n",
       "      <td>82.238745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient14</th>\n",
       "      <td>56.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient15</th>\n",
       "      <td>46.402083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient16</th>\n",
       "      <td>63.710847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient17</th>\n",
       "      <td>84.784175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient18</th>\n",
       "      <td>87.164951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient19</th>\n",
       "      <td>90.205428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient20</th>\n",
       "      <td>62.235136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient21</th>\n",
       "      <td>25.272845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient22</th>\n",
       "      <td>55.211519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient23</th>\n",
       "      <td>69.707914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient24</th>\n",
       "      <td>49.180186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient25</th>\n",
       "      <td>45.259951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient26</th>\n",
       "      <td>35.333908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient27</th>\n",
       "      <td>81.873746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient28</th>\n",
       "      <td>64.559367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient29</th>\n",
       "      <td>79.227049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient30</th>\n",
       "      <td>58.783946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phenoage\n",
       "patient1   74.348798\n",
       "patient2   67.372000\n",
       "patient3   74.789739\n",
       "patient4   46.991769\n",
       "patient5   44.559486\n",
       "patient6   72.509460\n",
       "patient7   57.377050\n",
       "patient8   31.779798\n",
       "patient9   50.356509\n",
       "patient10  67.696706\n",
       "patient11  62.601978\n",
       "patient12  41.735924\n",
       "patient13  82.238745\n",
       "patient14  56.677500\n",
       "patient15  46.402083\n",
       "patient16  63.710847\n",
       "patient17  84.784175\n",
       "patient18  87.164951\n",
       "patient19  90.205428\n",
       "patient20  62.235136\n",
       "patient21  25.272845\n",
       "patient22  55.211519\n",
       "patient23  69.707914\n",
       "patient24  49.180186\n",
       "patient25  45.259951\n",
       "patient26  35.333908\n",
       "patient27  81.873746\n",
       "patient28  64.559367\n",
       "patient29  79.227049\n",
       "patient30  58.783946"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.iloc[:, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_np = dataset.to_numpy()\n",
    "phenoages_np = np.array(adata.obs[\"phenoage\"], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_torch = torch.tensor(dataset_np, dtype=torch.float64)\n",
    "phenoages_torch = torch.tensor(phenoages_np, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    pred = clock(dataset_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[74.3488],\n",
       "        [67.3720],\n",
       "        [74.7897],\n",
       "        [46.9918],\n",
       "        [44.5595],\n",
       "        [72.5095],\n",
       "        [57.3771],\n",
       "        [31.7798],\n",
       "        [50.3565],\n",
       "        [67.6967],\n",
       "        [62.6020],\n",
       "        [41.7359],\n",
       "        [82.2387],\n",
       "        [56.6775],\n",
       "        [46.4021],\n",
       "        [63.7108],\n",
       "        [84.7842],\n",
       "        [87.1650],\n",
       "        [90.2054],\n",
       "        [62.2351],\n",
       "        [25.2728],\n",
       "        [55.2115],\n",
       "        [69.7079],\n",
       "        [49.1802],\n",
       "        [45.2600],\n",
       "        [35.3339],\n",
       "        [81.8737],\n",
       "        [64.5594],\n",
       "        [79.2270],\n",
       "        [58.7839]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Linear Regression Models for FHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([74.3488, 67.3720, 74.7897, 46.9918, 44.5595, 72.5095, 57.3770, 31.7798,\n",
       "        50.3565, 67.6967, 62.6020, 41.7359, 82.2387, 56.6775, 46.4021, 63.7108,\n",
       "        84.7842, 87.1649, 90.2054, 62.2351, 25.2728, 55.2115, 69.7079, 49.1802,\n",
       "        45.2600, 35.3339, 81.8737, 64.5594, 79.2271, 58.7839])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "manual_coefficients = np.array([\n",
    "    -0.0336,  0.0095,  0.1953,  0.0954, -0.0120,  0.0268,  0.3306,  0.0019, 0.0554,  0.0804\n",
    "])\n",
    "manual_intercept = np.array([\n",
    "    -19.9067\n",
    "])\n",
    "sklearn_model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "sklearn_model.n_features_in_ = len(manual_coefficients)\n",
    "sklearn_model.coef_ = manual_coefficients\n",
    "sklearn_model.intercept_ = manual_intercept\n",
    "\n",
    "raw_pred = sklearn_model.predict(dataset_np)\n",
    "pred_torch = torch.tensor(raw_pred, dtype=torch.float32)\n",
    "\n",
    "phenoage_post = PhenoAge()\n",
    "pred = phenoage_post.postprocess(pred_torch)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Attempt Torch) Quantize Model for FHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def test_in_fhe(quantized_numpy_module, X_test, y_test, simulate=True):\n",
    "    if not simulate:\n",
    "        print(\"Generating key\")\n",
    "        start_key = time.time()\n",
    "        quantized_numpy_module.fhe_circuit.keygen()\n",
    "        end_key = time.time()\n",
    "        print(f\"Key generation finished in {end_key - start_key:.2f} seconds\")\n",
    "\n",
    "    fhe_mode = \"simulate\" if simulate else \"execute\"\n",
    "\n",
    "    start_infer = time.time()\n",
    "    predictions = quantized_numpy_module.forward(X_test, fhe=fhe_mode).argmax(1)\n",
    "    end_infer = time.time()\n",
    "\n",
    "    if not simulate:\n",
    "        print(\n",
    "            f\"Inferences finished in {end_infer - start_infer:.2f} seconds \"\n",
    "            f\"({(end_infer - start_infer)/len(X_test):.2f} seconds/sample)\"\n",
    "        )\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(predictions == y_test) * 100\n",
    "    print(\n",
    "        \"FHE \" + (\"(simulation) \" * simulate) + f\"accuracy: {accuracy:.2f}% on \"\n",
    "        f\"{len(X_test)} examples.\"\n",
    "    )\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/projects/fhe-aging/pyaging/pyaging/models/_models.py:939: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  l = torch.tensor(0.0192, device=x.device, dtype=x.dtype)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "\n",
    "from concrete.ml.torch.compile import compile_torch_model\n",
    "\n",
    "# We need to unprune the model before compiling\n",
    "# clock.unprune()\n",
    "\n",
    "dataset_np_f32 = dataset_np.astype(np.float32)\n",
    "\n",
    "# print(\"dataset_np_f32.dtype:\", dataset_np_f32.dtype)\n",
    "\n",
    "# dataset_f32 = dataset_torch.to(torch.float32)\n",
    "\n",
    "clock = clock.to(torch.float32)\n",
    "\n",
    "# quantized_numpy_module = compile_brevitas_qat_model(clock, dataset_torch)\n",
    "quantized_module = compile_torch_model(\n",
    "    clock, # our model\n",
    "    dataset_np_f32, # a representative input-set to be used for both quantization and compilation\n",
    "    n_bits=8,\n",
    "    rounding_threshold_bits={\"n_bits\": 8, \"method\": \"approximate\"}\n",
    ")\n",
    "\n",
    "# prediction_simulated = test_in_fhe(quantized_numpy_module, dataset_torch, phenoages_torch, simulate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_np_f32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Values can only be constructed from arrays of signed and unsigned integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mquantized_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_np_f32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfhe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimulate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/ml/quantization/quantized_module.py:480\u001b[0m, in \u001b[0;36mQuantizedModule.forward\u001b[0;34m(self, fhe, debug, *x)\u001b[0m\n\u001b[1;32m    477\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdequantize_output(\u001b[38;5;241m*\u001b[39mto_tuple(q_y_pred))\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, debug_value_tracker\n\u001b[0;32m--> 480\u001b[0m q_y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfhe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfhe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# De-quantize the output predicted values\u001b[39;00m\n\u001b[1;32m    483\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdequantize_output(\u001b[38;5;241m*\u001b[39mto_tuple(q_y_pred))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/ml/quantization/quantized_module.py:523\u001b[0m, in \u001b[0;36mQuantizedModule.quantized_forward\u001b[0;34m(self, fhe, *q_x)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_forward(\u001b[38;5;241m*\u001b[39mq_x)\n\u001b[1;32m    522\u001b[0m simulate \u001b[38;5;241m=\u001b[39m fhe \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fhe_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/ml/quantization/quantized_module.py:688\u001b[0m, in \u001b[0;36mQuantizedModule._fhe_forward\u001b[0;34m(self, simulate, *q_x)\u001b[0m\n\u001b[1;32m    685\u001b[0m     predict_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfhe_circuit\u001b[38;5;241m.\u001b[39mencrypt_run_decrypt\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# Execute the forward pass in FHE or with simulation\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m q_result \u001b[38;5;241m=\u001b[39m to_tuple(\u001b[43mpredict_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mq_input\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(q_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(q_result_by_output), (\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of outputs does not match the number of output quantizers.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(q_result)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_quantizers)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elt_index, elt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(q_result):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/fhe/compilation/circuit.py:112\u001b[0m, in \u001b[0;36mCircuit.simulate\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Simulate execution of the circuit.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m            result of the simulation\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/fhe/compilation/module.py:188\u001b[0m, in \u001b[0;36mFheFunction.simulate\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Simulate execution of the function.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m            result of the simulation\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulate_decrypt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulate_run(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate_encrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/fhe/compilation/module.py:157\u001b[0m, in \u001b[0;36mFheFunction._simulate_encrypt\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_simulate_encrypt\u001b[39m(\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Optional[Union[\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, List]],\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Value, Tuple[Optional[Value], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_encrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/concrete/fhe/compilation/client.py:255\u001b[0m, in \u001b[0;36mClient.simulate_encrypt\u001b[0;34m(self, function_name, *args)\u001b[0m\n\u001b[1;32m    246\u001b[0m client_program \u001b[38;5;241m=\u001b[39m ClientProgram\u001b[38;5;241m.\u001b[39mcreate_simulated(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_specs\u001b[38;5;241m.\u001b[39mprogram_info)\n\u001b[1;32m    247\u001b[0m client_circuit \u001b[38;5;241m=\u001b[39m client_program\u001b[38;5;241m.\u001b[39mget_client_circuit(function_name)\n\u001b[1;32m    249\u001b[0m exported \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    250\u001b[0m     (\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m Value(\n\u001b[1;32m    254\u001b[0m             client_circuit\u001b[38;5;241m.\u001b[39msimulate_prepare_input(\n\u001b[0;32m--> 255\u001b[0m                 \u001b[43mValue_\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    256\u001b[0m                 position,\n\u001b[1;32m    257\u001b[0m             )\n\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m position, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ordered_sanitized_args)\n\u001b[1;32m    261\u001b[0m ]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(exported) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exported) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m exported[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Values can only be constructed from arrays of signed and unsigned integers."
     ]
    }
   ],
   "source": [
    "y_pred = quantized_module.forward(dataset_np_f32, fhe=\"simulate\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74.04157903],\n",
       "       [66.08271222],\n",
       "       [74.04157903],\n",
       "       [45.82377855],\n",
       "       [45.82377855],\n",
       "       [70.18273452],\n",
       "       [57.88266764],\n",
       "       [29.66486717],\n",
       "       [49.92380084],\n",
       "       [66.08271222],\n",
       "       [61.98268993],\n",
       "       [41.72375626],\n",
       "       [82.24162361],\n",
       "       [53.78264535],\n",
       "       [45.82377855],\n",
       "       [66.08271222],\n",
       "       [86.3416459 ],\n",
       "       [86.3416459 ],\n",
       "       [90.20049041],\n",
       "       [61.98268993],\n",
       "       [28.70015604],\n",
       "       [53.78264535],\n",
       "       [70.18273452],\n",
       "       [49.92380084],\n",
       "       [45.82377855],\n",
       "       [33.52371168],\n",
       "       [82.24162361],\n",
       "       [61.98268993],\n",
       "       [78.14160132],\n",
       "       [57.88266764]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
